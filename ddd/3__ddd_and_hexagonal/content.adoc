= Domain-Driven Design and the Hexagonal Architecture

:title: Domain-Driven Design and the Hexagonal Architecture
:author: Petter Holmstr√∂m
:description: Learn how to use the hexagonal architecture to turn your domain model into a complete application
:tags: domain-driven design, ddd, java, hexagonal, architecture, vaadin
:imagesdir: ./images

TODO

== Why Is It Called Hexagonal?

The name _hexagonal architecture_ comes from the way this architecture is usually depicted:

image:hexagonal.png[The hexagonal architecture]

Using hexagonals leaves plentiy of space for _ports and adapters_, which is another name for this architecture that better explains what the central idea is. The architecture is also sometimes called the _onion architecture_ because of how it is layered. 

.Hexagonal vs. Traditional Layers
****
TODO
image:layers.png[The traditional layered architecture]
****

.Hexagonal vs. Entity-Control-Boundary
****
If you have heard of the *Entity-Control-Boundary* pattern before, you will find the hexagonal architecture familiar. You can think of your aggregates as *entities*, domain services, factories and repositories as *controllers* and the application services as *boundaries*.
****

== The Domain Model

At the very core of the hexagonal architecture lies the domain model, implemented using the building blocks of tactical DDD that we covered in the previous article. This is where the so called business logic lives, where all the business decisions are made. This is also the most stable part of the software that hopefully will change the least (unless the business itself changes of course).

The domain model has been the subject of the previous two articles in this series so we are not going to cover it anymore here. However, the domain model alone does not provide any value if there is no way of interacting with it. To do that, we have to move up to the next layer in the "onion".

== Application Services

An application service acts as a facade through which clients will interact with the domain model. Application services have the following characteristics:

* They are stateless
* They enforce system security
* They control the database transactions
* They orchestrate business operations but do not make any business decisions (i.e. they do not contain any business logic)

Let's have a closer look at what this actually means.

=== Statelessness

An application service does not maintain any internal state that can be changed by interacting with clients. All the information that is needed to perform an operation should be available as input parameters to the application service method. This will make the system simpler and easier to debug and scale.

If you find yourself in a situation where you have to make multiple application service calls within the context of a single business process, you can model the business process in a class of its own and pass an instance of it as an input parameter to the applcation service method. The method would then do its magic and return an updated instance of the business process object that in turn can be used as input to other application service methods:

.Business process as input argument
[source,java]
----
public class MyBusinessProcess {
    // Current process state
}

public interface MyApplicationService {

    MyBusinessProcess performSomeStuff(MyBusinessProcess input);

    MyBusinessProcess performSomeMoreStuff(MyBusinessProcess input);
}
----

You could also make the business process object mutable and let the application service method change the state of the object directly. I personally do not prefer this approach since I believe it can lead to unwanted side effects, especially if the transaction ends up rolling back. This depends on how the application service is being called by the client and will return to this matter later in the section about ports and adapters.

=== Security Enforcement

The application service makes sure that the current user is allowed to perform the operation in question. Technically, you can do this manually at the top of each application service method or use something more sofisticated such as AOP. It does not matter how security is enforced as long as it happens in the application service layer and not inside the domain model. Now why is this important?

When we talk about security in an application, we tend to put more emphasis on preventing unauthorized access than on permitting authorized access. Thus, any security check we add to the system will essentially make it harder to use. If we add these security checks to the domain model, we may find ourselves in a situation where we are unable to perform an important operation because we did not think of it when the security checks were added and now they stand in the way. By keeping the all security checks out of the domain model, we get a more flexible system since we can interact with the domain model in any way we want. The system will still be safe since all clients are required to go through an application service anyway. It is way easier to create a new application service than to change the domain model.

==== Code Examples

TODO

=== Transaction Management

Every application service method should be designed in such a way that it forms a single transaction of its own, regardless of whether the underlying data storage uses transactions or not. If an application service method succeeds, there is no way of undoing it except by explicitly invoking another application service that reverses the operation (if such a method even exists).

If you find yourself in a situation where you would want to invoke multiple application service methods within the same transaction, you should check that the granularity of your application service is correct. Maybe some of the things your application service is doing should actually be in domain services instead? You may also need to consider redesigning your system to use eventual consistency instead of strong consistency (for more information about this, please check the previous article about tactical domain-driven design).

Technically, you can either handle the transactions manually inside the application service method or you can use the declarative transactions that are offered by frameworks and platforms such as Spring and Java EE.

==== Code Examples

TODO

=== Orchestration

Getting the orchestration right is perhaps the most difficult part of designing a good application service. This is because you need to make sure you are not accidentally introducing business logic into the application service even though you think you are only doing orchestration. So what does orchestration mean in this context?

By orchestration, I mean looking up and invoking the correct domain objects in the correct order, passing in the correct input parameters and returning the correct output. In its simplest form, an application service may look up an aggregate based on an ID, invoke a method on that aggregate, save it and return. However, in more complex cases, the method may have to look up multiple aggregates, interact with domain services, perform input validation and so on. If you find yourself writing long application service methods, you should ask yourself the following questions:

* Is the method making a business decision or asking the domain model to make the decision?
* Should some of the code be moved to domain event listeners?

This being said, having some business logic ending up in an application service method is not the end of the world. It is still pretty close to the domain model and well encapsulated and should be pretty easy to refactor into the domain model at a later time. Don't waste too much precious time thinking about whether something should go into the domain model or into the application service if it is not immediately clear to you.

==== Code Examples

TODO

=== Domain Event Listeners

In the previous article about tactical domain-driven design, we talked about domain events and domain event listeners. We did not, however, talk about where the domain event listeners fit into the overall system architecture. We recall from the previous article that a domain event listener should not be able to affect the outcome of the method that published the event in the first place. In practice, this means that a domain event listener should run inside its own transaction.

Because of this, I consider domain event listeners to be a special kind of application service that is invoked not by a client but by a domain event. This also means that a domain event listener is an orchestrator that should not contain any business logic. Depending on what needs to happen when a certain domain event is published, you may have to create a separate domain service that decides what to do with it if there are more than one path forward.

This being said, in the section about aggregates in the previous article, I mentioned that it may sometimes be justified to alter multiple aggregates within the same transaction even though this goes against the aggregate design guidelines. I also mentioned that this should preferably be made through domain events. In cases like this, the domain event listeners would have to participate in the current transaction and could thereby affect the outcome of the method that published the event, breaking the design guidelines for both domain events and application services. This is not the end of the world as long as you do it intentionally and are aware of the conequences you might face in the future. Sometimes you just have to be pragmatic.

=== Input and Output

One important decision when designing application services is to decide what data to consume (method parameters) and what data to return. You have three alternatives:

1. Use the entities and value objects directly from the domain model.
2. Use separate Data Transfer Objects (DTOs).
3. Use Domain Payload Objects (DPOs) that are a combination of the two above.

Each alternative has its own pros and cons, so let's have a closer look at each.

==== Entities and Aggregates

In the first alternative, the application services return entire aggregates (or parts thereof). The client can do whatever it wants with them and when it is time to save changes, the aggregates (or parts thereof) are passed back to the application service as parameters. 

This alternative works best when the domain model is anemic (i.e. it only contains data and no business logic) and the aggregates are small and stable (as in unlikely to change much in the near future). 

It also works if the client will be accessing the system through REST or SOAP and the aggregates can easily be serialized into JSON or XML and back. In this case, clients will not actually be interacting directly with your aggregates but with a JSON or XML representation of the aggregate that may be implemented in a completely different language. From the client's perspective, the aggregates are just DTOs.

The advantages with this alternative are:

* You can use the classes that you already have
* There is no need to convert between domain objects and DTOs.

The disadvantages are:

* It couples the domain model directly to the clients. If the domain model changes, you have to change your clients as well.
* It imposes restrictions on how you validate user input (more about this later).
* You have to design your aggregates in such a way that the client cannot put the aggregate into an inconsistent state or perform an operation that is not allowed.
* You may run into problems with lazy-loading of entities inside an aggregate (JPA).

==== Data Transfer Objects

In the second alternative, the application services consume and return data transfer objects. The DTOs can correspond to entities in the domain model, but more often they are designed for a specific application service or even a specific application service method. The application service is then responsible for moving data back and forth between the DTOs and the domain objects. 

This alternative works best when the domain model is very rich in business logic, the aggregates are complex or when the domain model is expected to change a lot while keeping the client API as stable as possible.

The advantages with this alternative are:

* The clients are decoupled from the domain model, making it easier to evolve it without having to change the clients.
* Only the data that is actually needed is being passed between the clients and the application services, improving performance (especially if the client and the application service are communicating over a network in a distributed environment).
* It becomes easier to control access to the domain model, especially if only certain users are allowed to invoke certain aggregate methods or view certain aggregate attribute values.
* Only application services will interact with the aggregates inside active transactions. This means you can utilize lazy loading of entities inside an aggregate (JPA).

The disadvantages are:

* You get a new set of DTO classes to maintain.
* You have to move data back and forth between DTOs and aggregates. This can be especially tedious if the DTOs and entities are almost similar in structure. If you work in a team you need to have a good explanation ready for why the separation of DTOs and aggregates is warranted. 

==== Domain Payload Objects

In the third alternative, application services consume and return domain payload objects. A domain payload object is a data transfer object that is aware of the domain model and can contain domain objects. This is essentially a combination of the first two alternatives.

This alternative works best in cases where the domain model is anemic, the aggregates are small and stable and you want to implement an operation that involves multiple different aggregates. Personally, I would say I use DPOs more often as output objects than as input objects.

The advantages with this alternative are:

* You do not need to create DTO classes for everything. When passing a domain object directly to the client is good enough, you do it. When you need a custom DTO, you create one. When you need both, you use both.

The disadvantages are:

* Same as for the first alternative. The disadvantages can be mitigated by only including immutable value objects inside the DPOs.

==== Code Examples

TODO

=== Input Validation

As we have mentioned previously, an aggregate must always be in a consistent state. This means among other things that we need to properly validate all the input that is used to alter the state of an aggregate. How and where do we do that?

From a user experience perspective, the user interface should include validation so that the user is not even able to perform an operation if the data is invalid. However, relying simply on user interface validation is _not good enough_ in a hexagonal system. The reason for this is that the user interface is but one of potentially many ports into the system. It does not help that the user interface is validating data properly if a REST endpoint lets any garbage through to the domain model.

When thinking about input validation there are actually two distinct kinds of validation: format validation and content validation. When we are validating the format, we check that certain values of certain types conform to certain rules. E.g. a social security number is expected to be in a specific pattern. When we are validating the content, we already have a wellformed piece of data and are interested in checking that that data makes sense. E.g. we may want to check that a well-formed social security number actually corresponds to a real person. You can implement these validations in different ways so lets have a closer look.

==== Format Validation

If you are using a lot of value objects in your domain model (I tend to do that personally) that are wrappers around primitive types (such as strings or integers), then it makes sense to build the format validation straight into your value object constructor. In other words, it should not be possible to create e.g. an `EmailAddress` or `SocialSecurityNumber` instance without passing in a well-formed argument. This has the added advantage that you can do some parsing and cleaning up inside the constructor if there are multiple known ways of entering valid data (e.g. when entering a phone number some people may use spaces or dashes to split the number into groups whereas others may not use any whitespace at all).

Now when the value objects are valid, how do we validate the entities that use them? There are two options available for Java developers.

The first option is to add the validation into your constructors, factories and setter methods. The idea here is that it should not even be possible to put an aggregate into an inconsistent state: all required fields must be populated in the constructor, any setters of required fields will not accept null parameters, other setters will not accept values of an incorrect format or length, etc. I personally tend to use this approach when I'm working with domain models that are very rich in business logic. It makes the domain model very robust, but also practically forces you to use DTOs bewteen clients and application services since it is more or less impossible to properly bind to a UI.

The second option is to use Java Bean Validation (JSR-303). Put annotations on all of the fields and make sure your application service runs the aggregate through the `Validator` before doing anything else with it. I personally tend to use this approach when I'm working with domain models that are anemic. Even though the aggregate itself does not prevent anybody from putting it into an inconsistent state, you can safely assume that all aggregates that have either been retrieved from a repository or have passed validation are consistent.

You can also combine both options by using the first option in your domain model and Java Bean Validation for your incoming DTOs or DPOs.

==== Content Validation

The simplest case of content validation is to make sure that two or more interdependent attributes within the same aggregate are valid (e.g. if one attribute is set, the other must be null and vice versa). You can either implement this directly into the entity class itself or use a class-level Java Bean Validation constraint. This type of content validation will come for free while performing format validation since it uses the same mechanisms.

A more complex case of content validation would be to check that a certain value exists (or does not exist) in a lookup list somewhere. This is very much the responsibility of the application service. Before allowing any business or persistence operations to continue, the application service should perform the lookup and throw an exception if needed. This is not something you want to put into your entities since the entities are movable domain objects whereas the objects needed for the lookup are typically static (see the previous article about tactical DDD for more information about movable and static objects).

The most complex case of content validation would be to verify an entire aggregate against a set of business rules. In this case the responsibility is split between the domain model and the application service. A domain service would be responsible for performing the validation itself, but the application service would be responsible for invoking the domain service.

==== Code Examples

TODO

=== Does the Size Matter?

Before we leave the subject of application services, there is one more thing I want to briefly mention. As with all facades, there is an ever-present risk of the application services growing into huge god classes that know too much and do too much. These types of classes are often hard to read and maintain simply because they are so large.

So how do you keep the application services small? The first step is of course to split a service that is growing too big into smaller services. However, there is a risk in this as well. I have seen situations where two services where so similar that developers did not know what the difference was between them, nor which method should go into which service. The result was that service methods were scattered over two separate service classes, and sometimes even implemented twice - once in each service - but by different developers.

When I design application services I try to make them as coherent as possible. In CRUD applications, this could mean one application service per aggregate. In more domain-driven applications, this could mean one application service per business process or even separate services for specific use cases or user interface views.

Naming is a very good guideline when designing application services. Try to name your application services according to what they do as opposed to which aggregates they concern. E.g. `EmployeeCrudService`  or `EmploymentContractTerminationService` are fare better names than `EmployeeService` which could mean anything.

Finally I just want to mention command based application services. In this case, you model each application service model as a command object with a corresponding command handler. This means that every application service contains exactly one method that handles exactly one command. You can use polymorphism to create specialized commands or command handlers. This approach results in a large number of small classes and is useful especially in applications whose user interfaces are inherently command-driven or where clients interact with application services through some kind of messaging mechanism such as a message queue (MQ) or enterprise service bus (ESB).

==== Code Examples

TODO

== Ports and Adapters

So far we have discussed the domain model and the application services that surround and interact with it. However, these application services are completely useless if there is no way for clients to invoke them and that is where ports and adapters enter the picture.

A port is an interface between the system and the outside world that has been especially designed for a particular type of protocol. Ports are not only used to allow outside clients access to the system but also to allow the system to access external systems.

Because ports can be designed for many different protocols, you have to pair them with adapters that know how to translate between the protocol and the application services and domain model.

You typically have a one-to-one mapping between ports and adapters but nothing prevents you from using the same adapter with different ports. You could, for instance, make your REST API available both using an HTTP port and a RabbitMQ port.

You can add as many ports and adapters as you like to a system and also remove obsolete ports and adapters that are no longer in use. This is one of the core strenghts of the hexagonal architecture - it is extendable and flexible.

This may all sound like a good idea but what are ports and adapters in practice? Let's have a look!

=== Example 1: A REST API

In the first example we are going to create a REST API for our Java application:

image:rest_adapter.png[A REST adapter and HTTP port]

The port is HTTP so we need a servlet to implement the port. The REST controller acts as the adapter. Naturally we are using a framework such as Spring or JAX-RS that provides both the servlet and mapping between POJOs (Plain Old Java Objects) and XML/JSON out-of-the-box. We only have to implement the REST controller which will:

1. Take either raw XML/JSON or deserialized POJOs as input,
2. Invoke the application services, 
3. Construct a response as either raw XML/JSON or as a POJO that will be serialized by the framework, and
4. Return the response to the client.

The clients, regardless of whether they are client-side web applications running in a browser or other systems running on their own servers, are not a part of this particular hexagonal system. The system also does not have to care about who the clients are as long as they comform to the protocol that the port and adapter supports.

=== Example 2: A Server-Side Vaadin UI

In the second example, we are going to look at a different type of adapter, namely a server-side Vaadin UI:

image:vaadin_adapter.png[A Vaadin adapter and HTTP port]

Again, the port is HTTP so we need a servlet to implement the port. In this case, the servlet is the `VaadinServlet` so we don't need to implement it ourselves. Now we just need an adapter for translating incoming user actions into application service method calls and the output into HTML that can be rendered in the browser. This adapter is the Vaadin UI. Thinking of the user interface as just another port/adapter into the system is an excellent way of keeping business logic outside of the user interface.

=== Example 3: Communicating with a Relational Database

In the third example, we are going to turn things around and look at a port and adapter that allows our system to call out to an external system, more specifically a relational database:

image:jdbc_adapter.png[A repository adapter and JDBC port]

This time, the port is JDBC and it is implemented by a JDBC driver (such as for H2, MySQL or PostgreSQL). The adapter is a set of implementations of the repository interfaces declared in the domain model. The adapter would also have to plug into the application service layer's transaction management API. You could interact with the JDBC drivers directly, but most Java applications would probably use a framework such as JPA or JOOQ. This framework would also be considered a part of the adapter.

In this case, the adapter is not invoking the application service. Instead, the application service is actually invoking the adapter, but through interfaces defined by the application service or domain model. For this to work properly, you need to use some kind of dependency injection so that the correct instances of the adapter classes are injected into the application services.

This is a use case that is perfectly OK in a hexagonal architecture, but would not have been permitted in a traditional layered architecture. The reason for this is that we would have a lower layer (the "infrastructure layer") depending on a higher layer (the "domain layer" and the "application layer").

=== Example 4: Communicating with an External System over REST

In the fourth and last example, we are going to look at a port and adapter that allows our system to call out to an external system over REST:

image:rest_client_adapter.png[A REST client adapter and HTTP port]

The port is again HTTP, but it is sending out requests and receiving responses instead of the other way around (as was the case in the first example). It is implemented by some suitable HTTP client, such as Apache HttpComponents.

The adapter implements a domain service interface. Like in the previous example, the adapter is injected into the application services using some kind of dependency injection. It then invokes the HTTP client to make calls to the external system and translates the received responses into domain objects.

== Multiple Bounded Contexts

So far we have only look at what the hexagonal architecture looks like when applied to a single bounded context. But what happens when you have multiple bounded contexts that need to communicate with each other?

If the contexts are running on separate systems and communicating over a network, you can do something like this: Create a REST API for the upstream system and a REST client adapter for the downstream system:

image:distributed.png[Two bounded contexts running on separate nodes]

The mapping between the different contexts would take place in the downstream system's adapter.

If the contexts are running as modules inside a single monolithing system, you can still use a similar architecture except you can leave the port out:

image:monolith.png[Two bounded contexts inside the same monolith]

Since both contexts are running inside the same virtual machine, we only need one adapter that interacts with both contexts directly. The adapter implements an interface of the downstream context and invokes application services of the upstream context. Any context mapping takes place inside the adapter.



== Next: Domain-Driven Design and Spring Boot

In the next and final article in this series, we are going to learn how to use Spring Boot to build applications using domain-driven design and the hexagonal architecture.
